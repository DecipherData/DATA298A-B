# -*- coding: utf-8 -*-
"""groung_dino_annotations_2500.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19ioaNG9LZrjwGbRGZKmUbKwpth4W0EBm
"""

!nvidia-smi

import os
HOME = os.getcwd()
print(HOME)



HOME = '/content/drive/MyDrive/Data298AandB/Grounding_Dino_new'

#!git clone https://github.com/IDEA-Research/GroundingDINO.git

!echo {HOME}

#!git clone https://github.com/IDEA-Research/Grounding_DINO.git

os.chdir(HOME + "/GroundingDINO")
os.getcwd()

!pip install -q -e .

!pip install -q roboflow

!pip install fastapi

!pip install kaleido

!pip install python-multipart

!pip install uvicorn

HOME

CONFIG_PATH = os.path.join(HOME, 'GroundingDINO/groundingdino/config/GroundingDINO_SwinB_cfg.py')
print(CONFIG_PATH, "; exists: ", os.path.isfile(CONFIG_PATH))

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}

#!mkdir {HOME}/weights

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}/weights

#!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha2/groundingdino_swinb_cogcoor.pth

WEIGHTS_NAME = 'groundingdino_swinb_cogcoor.pth'
WEIGHTS_PATH = os.path.join(HOME, "weights", WEIGHTS_NAME)
print(WEIGHTS_PATH, "; exists : ", os.path.isfile(WEIGHTS_PATH))

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}/GroundingDINO

from groundingdino.util.inference import load_model, load_image, predict, annotate

model = load_model(CONFIG_PATH, WEIGHTS_PATH)

HOME

# Commented out IPython magic to ensure Python compatibility.
import supervision as sv
# %matplotlib inline

#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/paper/paper 1311.jpg"

TEXT_PROMPT = "paper"
BOX_TRESHOLD = 0.30
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

sv.plot_image(annotated_frame, (10, 20))

import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device

import os
import cv2
import shutil
from PIL import UnidentifiedImageError

"""We will go through each class and tune.  

1. **clothes**

**clothes -train**
"""

# Define your class name and other constants here
class_name = "clothes"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/clothes"
detected_clothes_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/clothes/images_clothes"  # Folder for original detected images
detected_clothes_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/clothes/detected_clothes_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/clothes/labels_clothes"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/clothes/undetected_dir"
prompts = ["cloth"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9         10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", "e-waste"]

class_id = 5

# Create output folders if they don't exist
os.makedirs(detected_clothes_dir, exist_ok=True)
os.makedirs(detected_clothes_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.40, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_clothes_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_clothes_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""**clothes - val**"""

import os
import cv2
import shutil
from PIL import UnidentifiedImageError

# Define your class name and other constants here
class_name = "clothes"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/clothes"
detected_clothes_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/clothes/images_clothes"  # Folder for original detected images
detected_clothes_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/clothes/detected_clothes_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/clothes/labels_clothes"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/clothes/undetected_dir"
prompts = ["cloth"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 5

# Create output folders if they don't exist
os.makedirs(detected_clothes_dir, exist_ok=True)
os.makedirs(detected_clothes_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.40, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_clothes_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_clothes_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""2. **Furniture**

**furniture train**
"""

# Define your class name and other constants here
class_name = "furniture"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/furniture"
detected_furniture_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/furniture/images_furniture"  # Folder for original detected images
detected_furniture_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/furniture/detected_furniture_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/furniture/labels_furniture"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/furniture/undetected_dir"
prompts = ["furniture"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 6

# Create output folders if they don't exist
os.makedirs(detected_furniture_dir, exist_ok=True)
os.makedirs(detected_furniture_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.50, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_furniture_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_furniture_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""**furniture val**"""

# Define your class name and other constants here
class_name = "furniture"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/furniture"
detected_furniture_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/furniture/images_furniture"  # Folder for original detected images
detected_furniture_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/furniture/detected_furniture_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/furniture/labels_furniture"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/furniture/undetected_dir"
prompts = ["furniture"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 6

# Create output folders if they don't exist
os.makedirs(detected_furniture_dir, exist_ok=True)
os.makedirs(detected_furniture_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.50, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_furniture_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_furniture_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""3. **Shoes**

**shoes train**
"""

# Define your class name and other constants here
class_name = "shoes"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/shoes"
detected_shoes_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/shoes/images_shoes"  # Folder for original detected images
detected_shoes_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/shoes/detected_shoes_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/shoes/labels_shoes"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/shoes/undetected_dir"
prompts = ["shoe"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 7

# Create output folders if they don't exist
os.makedirs(detected_shoes_dir, exist_ok=True)
os.makedirs(detected_shoes_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.30, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_shoes_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_shoes_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""**shoes val**"""

# Define your class name and other constants here
class_name = "shoes"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/shoes"
detected_shoes_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/shoes/images_shoes"  # Folder for original detected images
detected_shoes_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/shoes/detected_shoes_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/shoes/labels_shoes"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/shoes/undetected_dir"
prompts = ["shoe"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 7

# Create output folders if they don't exist
os.makedirs(detected_shoes_dir, exist_ok=True)
os.makedirs(detected_shoes_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.30, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_shoes_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_shoes_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""4. **cardboard**

**cardboard train**
"""

# Define your class name and other constants here
class_name = "cardboard"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/cardboard"
detected_cardboard_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/cardboard/images_cardboard"  # Folder for original detected images
detected_cardboard_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/cardboard/detected_cardboard_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/cardboard/labels_cardboard"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/cardboard/undetected_dir"
prompts = ["cardboard", "cardboard box", "cardboard boxes", "cardboard DIY"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 0

# Create output folders if they don't exist
os.makedirs(detected_cardboard_dir, exist_ok=True)
os.makedirs(detected_cardboard_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.28, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_cardboard_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_cardboard_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""**cardboard val**"""

# Define your class name and other constants here
class_name = "cardboard"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/cardboard"
detected_cardboard_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/cardboard/images_cardboard"  # Folder for original detected images
detected_cardboard_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/cardboard/detected_cardboard_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/cardboard/labels_cardboard"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/cardboard/undetected_dir"
prompts = ["cardboard", "cardboard box", "cardboard boxes", "cardboard DIY"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 0

# Create output folders if they don't exist
os.makedirs(detected_cardboard_dir, exist_ok=True)
os.makedirs(detected_cardboard_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.28, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_cardboard_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_cardboard_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""5. **Paper**

**paper train**
"""

# Define your class name and other constants here
class_name = "paper"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/paper"
detected_paper_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/paper/images_paper"  # Folder for original detected images
detected_paper_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/paper/detected_paper_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/paper/labels_paper"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/paper/undetected_dir"
prompts = ["paper","paper carton", "paper container", "milk tetrapack","paper cup", "news paper"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 1

# Create output folders if they don't exist
os.makedirs(detected_paper_dir, exist_ok=True)
os.makedirs(detected_paper_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.30, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_paper_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_paper_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""**Paper val**"""

# Define your class name and other constants here
class_name = "paper"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/paper"
detected_paper_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/paper/images_paper"  # Folder for original detected images
detected_paper_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/paper/detected_paper_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/paper/labels_paper"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/paper/undetected_dir"
prompts = ["paper","paper carton", "paper container", "milk tetrapack","paper cup", "news paper"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 1

# Create output folders if they don't exist
os.makedirs(detected_paper_dir, exist_ok=True)
os.makedirs(detected_paper_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.30, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_paper_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_paper_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""6. **Plastic**

**Plastic train**
"""

# Define your class name and other constants here
class_name = "plastic"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/plastic"
detected_plastic_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/plastic/images_plastic"  # Folder for original detected images
detected_plastic_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/plastic/detected_plastic_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/plastic/labels_plastic"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/plastic/undetected_dir"
prompts = ["plastic", "plastic cup", "plastic jar", "plastic bottle"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 2

# Create output folders if they don't exist
os.makedirs(detected_plastic_dir, exist_ok=True)
os.makedirs(detected_plastic_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.28, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_plastic_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_plastic_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""**Plastic val**"""

# Define your class name and other constants here
class_name = "plastic"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/plastic"
detected_plastic_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/plastic/images_plastic"  # Folder for original detected images
detected_plastic_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/plastic/detected_plastic_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/plastic/labels_plastic"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/plastic/undetected_dir"
prompts = ["plastic", "plastic cup", "plastic jar", "plastic bottle"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 2

# Create output folders if they don't exist
os.makedirs(detected_plastic_dir, exist_ok=True)
os.makedirs(detected_plastic_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.28, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_plastic_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_plastic_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""7. **Metal**

**metal train**
"""

# Define your class name and other constants here
class_name = "metal"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/metal"
detected_metal_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/metal/images_metal"  # Folder for original detected images
detected_metal_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/metal/detected_metal_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/metal/labels_metal"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/metal/undetected_dir"
prompts = ["cans","can","metal", "metal rod"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 3

# Create output folders if they don't exist
os.makedirs(detected_metal_dir, exist_ok=True)
os.makedirs(detected_metal_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.30, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_metal_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_metal_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""**metal val**"""

# Define your class name and other constants here
class_name = "metal"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/metal"
detected_metal_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/metal/images_metal"  # Folder for original detected images
detected_metal_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/metal/detected_metal_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/metal/labels_metal"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/metal/undetected_dir"
prompts = ["cans","can","metal", "metal rod"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 3

# Create output folders if they don't exist
os.makedirs(detected_metal_dir, exist_ok=True)
os.makedirs(detected_metal_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.30, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_metal_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_metal_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""8. **Medical**

**Medical train**
"""

# Define your class name and other constants here
class_name = "medical"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/medical"
detected_medical_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/medical/images_medical"  # Folder for original detected images
detected_medical_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/medical/detected_medical_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/medical/labels_medical"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/medical/undetected_dir"
prompts = ["medicine", "capsule", "capsules", "hand glove", "blue mask", "black mask"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 4

# Create output folders if they don't exist
os.makedirs(detected_medical_dir, exist_ok=True)
os.makedirs(detected_medical_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.30, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_medical_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_medical_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""**Medical val**"""

# Define your class name and other constants here
class_name = "medical"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/medical"
detected_medical_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/medical/images_medical"  # Folder for original detected images
detected_medical_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/medical/detected_medical_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/medical/labels_medical"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/medical/undetected_dir"
prompts = ["medicine", "capsule", "capsules", "hand glove", "blue mask", "black mask"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 4

# Create output folders if they don't exist
os.makedirs(detected_medical_dir, exist_ok=True)
os.makedirs(detected_medical_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.30, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_medical_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_medical_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""9. **biowaste**

**biowaste train**
"""

# Define your class name and other constants here
class_name = "biowaste"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/biowaste"
detected_biowaste_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/biowaste/images_biowaste"  # Folder for original detected images
detected_biowaste_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/biowaste/detected_biowaste_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/biowaste/labels_biowaste"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/biowaste/undetected_dir"
prompts = ["food","organic", "crops", "lentils","biowaste","biodegradable",
           "meat","fries","vegetable","green plant",
           "fruits","vegetable","cereal", "green vegetable"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 8

# Create output folders if they don't exist
os.makedirs(detected_biowaste_dir, exist_ok=True)
os.makedirs(detected_biowaste_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.25, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_biowaste_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_biowaste_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""**biowaste val**"""

# Define your class name and other constants here
class_name = "biowaste"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/biowaste"
detected_biowaste_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/biowaste/images_biowaste"  # Folder for original detected images
detected_biowaste_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/biowaste/detected_biowaste_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/biowaste/labels_biowaste"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/biowaste/undetected_dir"
prompts = ["food","organic", "crops", "lentils","biowaste","biodegradable",
           "meat","fries","vegetable","green plant",
           "fruits","vegetable","cereal", "green vegetable"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", e-waste"]

class_id = 8

# Create output folders if they don't exist
os.makedirs(detected_biowaste_dir, exist_ok=True)
os.makedirs(detected_biowaste_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.25, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_biowaste_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_biowaste_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""10. **glass**

**glass train**
"""

# Define your class name and other constants here
class_name = "glass"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/glass"
detected_glass_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/glass/images_glass"  # Folder for original detected images
detected_glass_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/glass/detected_glass_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/glass/labels_glass"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/glass/undetected_dir"
prompts = ["bottle","glass","green bottle", "bottles", "brown bottles ",
"soda bottles","glass mug", "glass cup", "glass objects", "green cups","glass apparatus"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", "e-waste"]

class_id = 9

# Create output folders if they don't exist
os.makedirs(detected_glass_dir, exist_ok=True)
os.makedirs(detected_glass_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.28, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_glass_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_glass_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""**glass val**"""

# Define your class name and other constants here
class_name = "glass"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/glass"
detected_glass_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/glass/images_glass"  # Folder for original detected images
detected_glass_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/glass/detected_glass_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/glass/labels_glass"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/glass/undetected_dir"
prompts = ["bottle","glass","green bottle", "bottles", "brown bottles ",
"soda bottles","glass mug", "glass cup", "glass objects", "green cups","glass apparatus"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", "e-waste"]

class_id = 9

# Create output folders if they don't exist
os.makedirs(detected_glass_dir, exist_ok=True)
os.makedirs(detected_glass_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.28, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_glass_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_glass_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""11. **E-waste**

**e-waste train**
"""

# Define your class name and other constants here
class_name = "e-waste"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/e-waste"
detected_ewaste_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/e-waste/images_ewaste"  # Folder for original detected images
detected_ewaste_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/e-waste/detected_ewaste_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/e-waste/labels_ewaste"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/e-waste/undetected_dir"
prompts = ["electronic", "mobile phone", "laptop", "hair dryer","vacuum cleaner"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", "e-waste"]

class_id = 10

# Create output folders if they don't exist
os.makedirs(detected_ewaste_dir, exist_ok=True)
os.makedirs(detected_ewaste_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.28, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_ewaste_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_ewaste_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

"""**e-waste val**"""

# Define your class name and other constants here
class_name = "e-waste"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/e-waste"
detected_ewaste_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/e-waste/images_ewaste"  # Folder for original detected images
detected_ewaste_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/e-waste/detected_ewaste_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/e-waste/labels_ewaste"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/val/e-waste/undetected_dir"
prompts = ["electronic", "mobile phone", "laptop", "hair dryer","vacuum cleaner"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", "e-waste"]

class_id = 10

# Create output folders if they don't exist
os.makedirs(detected_ewaste_dir, exist_ok=True)
os.makedirs(detected_ewaste_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.28, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_ewaste_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_ewaste_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

'/content/drive/MyDrive/Data298AandB/Grounding_DINO/undetected/glass/372_glass 1639.jpg'

# Commented out IPython magic to ensure Python compatibility.

#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test_2500/train_val_test/train/furniture/54_Table--142-_jpg.rf.9afededdfc9164713bd9b04b7753d909.jpg"

TEXT_PROMPT = "furniture"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (10, 20))

# Commented out IPython magic to ensure Python compatibility.
import supervision as sv

#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/undetected/paper/221_paper 1140.jpg"

TEXT_PROMPT = "milk paper tetrapack"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))



# Commented out IPython magic to ensure Python compatibility.
import supervision as sv

#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/YOLO_Modeling/data/OriginalDataset/OrgData/FinalData/metal/metal 996.jpg"

TEXT_PROMPT = "shiny object"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))

# Commented out IPython magic to ensure Python compatibility.
import supervision as sv

#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/YOLO_Modeling/data/OriginalDataset/OrgData/FinalData/medical/medical 996.jpg"

TEXT_PROMPT = "plastic"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))

# Commented out IPython magic to ensure Python compatibility.

#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/YOLO_Modeling/data/OriginalDataset/OrgData/FinalData/glass/glass 991.jpg"

TEXT_PROMPT = "glass"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))

# Commented out IPython magic to ensure Python compatibility.


#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/YOLO_Modeling/data/OriginalDataset/OrgData/FinalData/furniture/Sofa--354-_jpg.rf.23c663ebcb784dd222a76740746b3dd4.jpg"

TEXT_PROMPT = "furniture"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))

# Commented out IPython magic to ensure Python compatibility.
#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/YOLO_Modeling/data/OriginalDataset/OrgData/FinalData/clothes/clothes990.jpg"

TEXT_PROMPT = "clothes"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))

# Commented out IPython magic to ensure Python compatibility.
import supervision as sv

#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/YOLO_Modeling/data/OriginalDataset/OrgData/FinalData/cardboard/cardboard 998.jpg"

TEXT_PROMPT = "cardboard"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))

# Commented out IPython magic to ensure Python compatibility.
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/YOLO_Modeling/data/OriginalDataset/OrgData/FinalData/bananapeel1.jpg"

TEXT_PROMPT = "biowaste"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))