# -*- coding: utf-8 -*-
"""groung_dino_annotations_old.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14pj8CfCsmaMg_N9uO8mGdnuhVEudVNLh
"""

!nvidia-smi

import os
HOME = os.getcwd()
print(HOME)



HOME = '/content/drive/MyDrive/Data298AandB/Grounding_Dino_new'

os.chdir(HOME)
os.getcwd()

!git clone https://github.com/IDEA-Research/GroundingDINO.git

!echo {HOME}

#!git clone https://github.com/IDEA-Research/Grounding_DINO.git

os.chdir(HOME + "/GroundingDINO")
os.getcwd()

!pip install -q -e .

!pip install -q roboflow

!pip install fastapi

!pip install kaleido

!pip install python-multipart

!pip install uvicorn

HOME

CONFIG_PATH = os.path.join(HOME, 'GroundingDINO/groundingdino/config/GroundingDINO_SwinB_cfg.py')
print(CONFIG_PATH, "; exists: ", os.path.isfile(CONFIG_PATH))

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}

!mkdir {HOME}/weights

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}/weights

#!wget -q https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha2/groundingdino_swinb_cogcoor.pth

WEIGHTS_NAME = 'groundingdino_swinb_cogcoor.pth'
WEIGHTS_PATH = os.path.join(HOME, "weights", WEIGHTS_NAME)
print(WEIGHTS_PATH, "; exists : ", os.path.isfile(WEIGHTS_PATH))

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}/GroundingDINO

from groundingdino.util.inference import load_model, load_image, predict, annotate

model = load_model(CONFIG_PATH, WEIGHTS_PATH)

HOME

# Commented out IPython magic to ensure Python compatibility.
import supervision as sv
# %matplotlib inline

#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/undetected/paper/paper 1311.jpg"

TEXT_PROMPT = "paper cups"
BOX_TRESHOLD = 0.40
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

sv.plot_image(annotated_frame, (10, 20))

"""**GLASS CATEGORY**"""

import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device

import os
import cv2
import shutil
from PIL import UnidentifiedImageError

# Define your class name and other constants here
class_name = "clothes"
class_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/undetected/clothes"
detected_clothes_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/undetected/clothes/detected_clothes"  # Folder for original detected images
detected_clothes_with_bb_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/undetected/clothes/detected_clothes_with_bb"  # Folder for detected images with bounding boxes
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/undetected/clothes/output_labels_dir"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/undetected/clothes/undetected_dir"
prompts = ["cloth"]  # List your prompts here

#class_ids = {"glass": 10}  # Example class IDs
#                   0         1         2         3        4           5          6           7          8          9        10
#class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "e-waste", "glass"]

class_id = 5

# Create output folders if they don't exist
os.makedirs(detected_clothes_dir, exist_ok=True)
os.makedirs(detected_clothes_with_bb_dir, exist_ok=True)
os.makedirs(output_labels_dir, exist_ok=True)
os.makedirs(undetected_dir, exist_ok=True)

initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])
undetected_images = []

for filename in os.listdir(class_dir):
    if filename.endswith(".jpg"):
        image_path = os.path.join(class_dir, filename)
        label_filename = os.path.splitext(filename)[0] + ".txt"
        label_filepath = os.path.join(output_labels_dir, label_filename)

        # Load the original image once outside the prompts loop
        image_cv_original = cv2.imread(image_path)
        detected = False
        # Assuming image_cv_original is the numpy array you want to process
        # Convert numpy array to a float tensor and rearrange dimensions if needed
        image_tensor = torch.from_numpy(image_cv_original).float()
        # If your model expects the image in [C, H, W] format, you need to permute the dimensions
        # This is common if the original image has shape [H, W, C] as with images loaded by OpenCV
        image_tensor = image_tensor.permute(2, 0, 1)
        image_tensor = image_tensor.to(device)

        for prompt in prompts:
            if detected:
                break  # Skip remaining prompts if detected

            # Your existing detection logic here, replace `prompt` with the current prompt in the loop
            # Assuming predict function is modified to accept prompt argument
            boxes, _, _ = predict(model=model, image=image_tensor, caption=prompt, box_threshold=0.30, text_threshold=0.25)

            if boxes.numel() > 0:
                detected = True
                image_cv = image_cv_original.copy()  # Make a copy of the original image for drawing

                # Draw bounding boxes and class names on the copy
                for box in boxes:
                  x_center, y_center, width, height = box.tolist()

                  # Convert from center coordinates to corner coordinates
                  x_min = int((x_center - width / 2) * image_cv.shape[1])
                  y_min = int((y_center - height / 2) * image_cv.shape[0])
                  x_max = int((x_center + width / 2) * image_cv.shape[1])
                  y_max = int((y_center + height / 2) * image_cv.shape[0])

                  # Draw the bounding box
                  cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                  # Put the class name
                  cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                # Save the copy with drawn bounding boxes
                output_image_path_with_bb = os.path.join(detected_clothes_with_bb_dir, filename)
                cv2.imwrite(output_image_path_with_bb, image_cv)

                # Move the original detected image to the detected_glass directory
                output_image_path_original = os.path.join(detected_clothes_dir, filename)
                shutil.copy(image_path, output_image_path_original)

                # Write bounding box information to the text file
                with open(label_filepath, "w") as label_file:
                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()
                        entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                        label_file.write(entry)

        if not detected:
            undetected_images.append(image_path)

# Move undetected images to a specific undetected folder
undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
os.makedirs(undetected_class_dir, exist_ok=True)
for undetected_image in undetected_images:
    shutil.copy(undetected_image, undetected_class_dir)

# Print statistics
print(f"Initial number of images in {class_name} folder: {initial_image_count}")
print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
print(f"Undetected images: {len(undetected_images)}")

'/content/drive/MyDrive/Data298AandB/Grounding_DINO/undetected/glass/372_glass 1639.jpg'

# Commented out IPython magic to ensure Python compatibility.

#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/undetected/medical/642_medical 1384.jpg"

TEXT_PROMPT = "white medicines"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (10, 20))

# Commented out IPython magic to ensure Python compatibility.
import supervision as sv

#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/undetected/paper/221_paper 1140.jpg"

TEXT_PROMPT = "milk paper tetrapack"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))



# Commented out IPython magic to ensure Python compatibility.
import supervision as sv

#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/YOLO_Modeling/data/OriginalDataset/OrgData/FinalData/metal/metal 996.jpg"

TEXT_PROMPT = "shiny object"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))

# Commented out IPython magic to ensure Python compatibility.
import supervision as sv

#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/YOLO_Modeling/data/OriginalDataset/OrgData/FinalData/medical/medical 996.jpg"

TEXT_PROMPT = "plastic"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))

# Commented out IPython magic to ensure Python compatibility.

#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/YOLO_Modeling/data/OriginalDataset/OrgData/FinalData/glass/glass 991.jpg"

TEXT_PROMPT = "glass"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))

# Commented out IPython magic to ensure Python compatibility.


#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/YOLO_Modeling/data/OriginalDataset/OrgData/FinalData/furniture/Sofa--354-_jpg.rf.23c663ebcb784dd222a76740746b3dd4.jpg"

TEXT_PROMPT = "furniture"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))

# Commented out IPython magic to ensure Python compatibility.
#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/YOLO_Modeling/data/OriginalDataset/OrgData/FinalData/clothes/clothes990.jpg"

TEXT_PROMPT = "clothes"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))

# Commented out IPython magic to ensure Python compatibility.
import supervision as sv

#IMAGE_NAME = "shoes988.jpg"
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/YOLO_Modeling/data/OriginalDataset/OrgData/FinalData/cardboard/cardboard 998.jpg"

TEXT_PROMPT = "cardboard"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))

# Commented out IPython magic to ensure Python compatibility.
IMAGE_PATH = "/content/drive/MyDrive/Data298AandB/YOLO_Modeling/data/OriginalDataset/OrgData/FinalData/bananapeel1.jpg"

TEXT_PROMPT = "biowaste"
BOX_TRESHOLD = 0.50
TEXT_TRESHOLD = 0.25

image_source, image = load_image(IMAGE_PATH)

boxes, logits, phrases = predict(
    model=model,
    image=image,
    caption=TEXT_PROMPT,
    box_threshold=BOX_TRESHOLD,
    text_threshold=TEXT_TRESHOLD
)

print("boxes", boxes)
print("logits", logits)
print("phrases",phrases)

annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)

# %matplotlib inline
sv.plot_image(annotated_frame, (5, 5))

"""**Entries without detection to go in a separate folder so those can be annotated manually**

**The data used here is train_test_val data for annotations**

## Just Images and labels folder

Final Code below - After this code was processed ewaste was the least detected category. Therefore, added more images of ewaste by scraping Google
"""

import os
import cv2
import shutil
from PIL import UnidentifiedImageError

# Define paths
base_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/train_before"
output_images_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output/images/" #output folder renamed to output_train later for clarity
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output/labels/"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output/undetected/"

#                   0         1         2         3        4           5          6           7          8          9        10
class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "glass", "e-waste"]

prompts = ["cardboard or cardboard box or brown cardboard",
          "paper or stacked paper cups or newspaper",
          "plastic or stacked plastic cups or plastic containers",
          "shiny object",
          "medicine or syringe or mask or gloves or capsule or tablet",
          "clothes or shoes or hair accessory or shirt or trouser or skirt or tie or belt or cap or hat",
          "furniture",
          "shoes or footwear or sandals or boots or flipflops",
          "food or rotten fruit or fruit peels or rotten vegetables or dairy or meat or poultry or seeds",
          "electronic or mobile or laptop or wires or motherboard or electronic chip or battery or semiconductor or cable or switch or charger or appliance",
          "glass or colorful glass or bottles"]

# Load class IDs
class_ids = {class_name: idx for idx, class_name in enumerate(class_names)}

# Initialize counters
undetected_count = 0

# Iterate through each class
for class_name, prompt in zip(class_names, prompts):
    class_dir = os.path.join(base_dir, class_name)

    # Get the initial number of images
    initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])

    print(f"Processing images in {class_name} folder")

    # Create output folders if they don't exist
    os.makedirs(output_images_dir, exist_ok=True)
    os.makedirs(output_labels_dir, exist_ok=True)

    # Initialize lists to store undetected images
    undetected_images = []

    # Iterate through each image in the class folder
    for filename in os.listdir(class_dir):
        if filename.endswith(".jpg"):
            image_path = os.path.join(class_dir, filename)

            # Check if the corresponding text file already exists
            label_filename = os.path.splitext(filename)[0] + ".txt"
            label_filepath = os.path.join(output_labels_dir, label_filename)

            try:
                # Process the image and get bounding boxes
                image_source, image = load_image(image_path)
                boxes, _, _ = predict(model=model, image=image, caption=prompt, box_threshold=0.5, text_threshold=0.25)

                # Get class ID
                class_id = class_ids[class_name]

                # Check if the bounding boxes are detected
                if boxes.numel() > 0:
                  # Load the image using OpenCV
                    image_cv = cv2.imread(image_path)

                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()

                        # Convert from center coordinates to corner coordinates
                        x_min = int((x_center - width / 2) * image_cv.shape[1])
                        y_min = int((y_center - height / 2) * image_cv.shape[0])
                        x_max = int((x_center + width / 2) * image_cv.shape[1])
                        y_max = int((y_center + height / 2) * image_cv.shape[0])

                        # Draw the bounding box
                        cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                        # Put the class name
                        cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                    # Save the modified image to the output folder instead of copying the original image
                    output_image_path = os.path.join(output_images_dir, filename)
                    cv2.imwrite(output_image_path, image_cv)

                    # # Copy the image to the output folder
                    # output_image_path = os.path.join(output_images_dir, filename)
                    # shutil.copy(image_path, output_image_path)

                    # Write bounding box information to the text file
                    with open(label_filepath, "w") as label_file:
                        for box in boxes:
                            x_center, y_center, width, height = box.tolist()
                            entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                            label_file.write(entry)
                else:
                    # If no boxes are detected, move the image to the undetected folder
                    undetected_images.append(image_path)

            except UnidentifiedImageError as e:
                print(f"Error processing image: {image_path}")
                print(f"Error details: {e}")
                continue

    # Move undetected images to the undetected folder
    undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
    os.makedirs(undetected_class_dir, exist_ok=True)
    for undetected_image in undetected_images:
        shutil.copy(undetected_image, undetected_class_dir)

    # Print statistics
    print(f"Initial number of images in {class_name} folder: {initial_image_count}")
    print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
    print(f"Undetected images: {len(undetected_images)}")

"""**Glass is not getting detected so fetching images and labels again**"""

import os
import cv2
import shutil
from PIL import UnidentifiedImageError

# Define paths
base_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/train_before"
output_images_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output/images/"
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output/labels/"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output/undetected/"

# Define class names and corresponding prompts
#class_names = ["class1", "class2", "class3", "class4", "class5", "class6", "class7", "class8", "class9", "class10", "class11"]
#prompts = ["prompt1", "prompt2", "prompt3", "prompt4", "prompt5", "prompt6", "prompt7", "prompt8", "prompt9", "prompt10", "prompt11"]

class_names = ["glass"] #["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "e-waste", "glass"]

prompts = ["glass or colorful glass or bottles"]

'''
  ["cardboard or cardboard box or brown cardboard",
          "paper or stacked paper cups or newspaper",
          "plastic or stacked plastic cups or plastic containers",
          "shiny object",
          "medicine or syringe or mask or gloves or capsule or tablet",
          "clothes or shoes or hair accessory or shirt or trouser or skirt or tie or belt or cap or hat",
          "furniture",
          "shoes or footwear or sandals or boots or flipflops",
          "food or rotten fruit or fruit peels or rotten vegetables or dairy or meat or poultry or seeds",
          "electronic or mobile or laptop or wires or motherboard or electronic chip or battery or semiconductor or cable or switch or charger or appliance",
          "glass or colorful glass or bottles"]
'''

# Load class IDs
#class_ids = {class_name: idx for idx, class_name in enumerate(class_names)}
class_ids = 10

# Initialize counters
undetected_count = 0

# Iterate through each class
for class_name, prompt in zip(class_names, prompts):
    class_dir = os.path.join(base_dir, class_name)

    # Get the initial number of images
    initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])

    print(f"Processing images in {class_name} folder")

    # Create output folders if they don't exist
    os.makedirs(output_images_dir, exist_ok=True)
    os.makedirs(output_labels_dir, exist_ok=True)

    # Initialize lists to store undetected images
    undetected_images = []

    # Iterate through each image in the class folder
    for filename in os.listdir(class_dir):
        if filename.endswith(".jpg"):
            image_path = os.path.join(class_dir, filename)
            print("image_path", image_path)

            # Check if the corresponding text file already exists
            label_filename = os.path.splitext(filename)[0] + ".txt"
            label_filepath = os.path.join(output_labels_dir, label_filename)

            try:
                # Process the image and get bounding boxes
                image_source, image = load_image(image_path)
                boxes, _, _ = predict(model=model, image=image, caption=prompt, box_threshold=0.5, text_threshold=0.25)

                # Get class ID
                #class_id = class_ids[class_name]
                class_id = 10

                # Check if the bounding boxes are detected
                if boxes.numel() > 0:
                    # Copy the image to the output folder
                    output_image_path = os.path.join(output_images_dir, filename)
                    shutil.copy(image_path, output_image_path)

                    # Write bounding box information to the text file
                    with open(label_filepath, "w") as label_file:
                        for box in boxes:
                            x_center, y_center, width, height = box.tolist()
                            entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                            label_file.write(entry)
                else:
                    # If no boxes are detected, move the image to the undetected folder
                    undetected_images.append(image_path)

            except UnidentifiedImageError as e:
                print(f"Error processing image: {image_path}")
                print(f"Error details: {e}")
                continue

    # Move undetected images to the undetected folder
    undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
    os.makedirs(undetected_class_dir, exist_ok=True)
    for undetected_image in undetected_images:
        shutil.copy(undetected_image, undetected_class_dir)

    # Print statistics
    print(f"Initial number of images in {class_name} folder: {initial_image_count}")
    print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
    print(f"Undetected images: {len(undetected_images)}")

#Copy the above file to the train_val_test to data/train/images and data/train/labels

import os
import shutil

# Define source and destination directories
source_images_dir = '/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output_train/images/' #should be output_train now
source_labels_dir = '/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output_train/labels/'
destination_images_dir = '/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/data/train/images/'
destination_labels_dir = '/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/data/train/labels/'

# Create destination directories if they don't exist
os.makedirs(destination_images_dir, exist_ok=True)
os.makedirs(destination_labels_dir, exist_ok=True)

# Get list of image files
image_files = os.listdir(source_images_dir)

# Copy image files
for image_file in image_files:
    source_image_path = os.path.join(source_images_dir, image_file)
    destination_image_path = os.path.join(destination_images_dir, image_file)
    if not os.path.exists(destination_image_path):
        shutil.copyfile(source_image_path, destination_image_path)
        print(f"Copied {source_image_path} to {destination_image_path}")

# Get list of label files
label_files = os.listdir(source_labels_dir)

# Copy label files
for label_file in label_files:
    source_label_path = os.path.join(source_labels_dir, label_file)
    destination_label_path = os.path.join(destination_labels_dir, label_file)
    if not os.path.exists(destination_label_path):
        shutil.copyfile(source_label_path, destination_label_path)
        print(f"Copied {source_label_path} to {destination_label_path}")

## Need to verify data/train/Images and Labels

"""Validation Data"""

import os
import cv2
import shutil
from PIL import UnidentifiedImageError

# Define paths
base_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/val_before"
output_images_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output_val/images/"
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output_val/labels/"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output_val/undetected/"

class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "e-waste", "glass"]

prompts = ["cardboard or cardboard box or brown cardboard",
          "paper or stacked paper cups or newspaper",
          "plastic or stacked plastic cups or plastic containers",
          "shiny object",
          "medicine or syringe or mask or gloves or capsule or tablet",
          "clothes or shoes or hair accessory or shirt or trouser or skirt or tie or belt or cap or hat",
          "furniture",
          "shoes or footwear or sandals or boots or flipflops",
          "food or rotten fruit or fruit peels or rotten vegetables or dairy or meat or poultry or seeds",
          "electronic or mobile or laptop or wires or motherboard or electronic chip or battery or semiconductor or cable or switch or charger or appliance",
          "glass or colorful glass or bottles"]

# Load class IDs
class_ids = {class_name: idx for idx, class_name in enumerate(class_names)}

# Initialize counters
undetected_count = 0

# Iterate through each class
for class_name, prompt in zip(class_names, prompts):
    class_dir = os.path.join(base_dir, class_name)

    # Get the initial number of images
    initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])

    print(f"Processing images in {class_name} folder")

    # Create output folders if they don't exist
    os.makedirs(output_images_dir, exist_ok=True)
    os.makedirs(output_labels_dir, exist_ok=True)

    # Initialize lists to store undetected images
    undetected_images = []

    # Iterate through each image in the class folder
    for filename in os.listdir(class_dir):
        if filename.endswith(".jpg"):
            image_path = os.path.join(class_dir, filename)

            # Check if the corresponding text file already exists
            label_filename = os.path.splitext(filename)[0] + ".txt"
            label_filepath = os.path.join(output_labels_dir, label_filename)

            try:
                # Process the image and get bounding boxes
                image_source, image = load_image(image_path)
                boxes, _, _ = predict(model=model, image=image, caption=prompt, box_threshold=0.5, text_threshold=0.25)

                # Get class ID
                class_id = class_ids[class_name]

                # Check if the bounding boxes are detected
                if boxes.numel() > 0:
                  # Load the image using OpenCV
                    image_cv = cv2.imread(image_path)

                    for box in boxes:
                        x_center, y_center, width, height = box.tolist()

                        # Convert from center coordinates to corner coordinates
                        x_min = int((x_center - width / 2) * image_cv.shape[1])
                        y_min = int((y_center - height / 2) * image_cv.shape[0])
                        x_max = int((x_center + width / 2) * image_cv.shape[1])
                        y_max = int((y_center + height / 2) * image_cv.shape[0])

                        # Draw the bounding box
                        cv2.rectangle(image_cv, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

                        # Put the class name
                        cv2.putText(image_cv, class_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36,255,12), 2)

                    # Save the modified image to the output folder instead of copying the original image
                    output_image_path = os.path.join(output_images_dir, filename)
                    cv2.imwrite(output_image_path, image_cv)

                    # # Copy the image to the output folder
                    # output_image_path = os.path.join(output_images_dir, filename)
                    # shutil.copy(image_path, output_image_path)

                    # Write bounding box information to the text file
                    with open(label_filepath, "w") as label_file:
                        for box in boxes:
                            x_center, y_center, width, height = box.tolist()
                            entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                            label_file.write(entry)
                else:
                    # If no boxes are detected, move the image to the undetected folder
                    undetected_images.append(image_path)

            except UnidentifiedImageError as e:
                print(f"Error processing image: {image_path}")
                print(f"Error details: {e}")
                continue

    # Move undetected images to the undetected folder
    undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
    os.makedirs(undetected_class_dir, exist_ok=True)
    for undetected_image in undetected_images:
        shutil.copy(undetected_image, undetected_class_dir)

    # Print statistics
    print(f"Initial number of images in {class_name} folder: {initial_image_count}")
    print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
    print(f"Undetected images: {len(undetected_images)}")

#Copy the above file to the train_val_test to data/val/images and data/val/labels

import os
import shutil

# Define source and destination directories
source_images_dir = '/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output_val/images/' #should be output_train now
source_labels_dir = '/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output_val/labels/'
destination_images_dir = '/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/data/val/images/'
destination_labels_dir = '/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/data/val/labels/'

# Create destination directories if they don't exist
os.makedirs(destination_images_dir, exist_ok=True)
os.makedirs(destination_labels_dir, exist_ok=True)

# Get list of image files
image_files = os.listdir(source_images_dir)

# Copy image files
for image_file in image_files:
    source_image_path = os.path.join(source_images_dir, image_file)
    destination_image_path = os.path.join(destination_images_dir, image_file)
    if not os.path.exists(destination_image_path):
        shutil.copyfile(source_image_path, destination_image_path)
        print(f"Copied {source_image_path} to {destination_image_path}")

# Get list of label files
label_files = os.listdir(source_labels_dir)

# Copy label files
for label_file in label_files:
    source_label_path = os.path.join(source_labels_dir, label_file)
    destination_label_path = os.path.join(destination_labels_dir, label_file)
    if not os.path.exists(destination_label_path):
        shutil.copyfile(source_label_path, destination_label_path)
        print(f"Copied {source_label_path} to {destination_label_path}")

"""Testing Data"""

import os
import cv2
import shutil
from PIL import UnidentifiedImageError

# Define paths
base_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/test_before"
output_images_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output_test/images/"
output_labels_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output_test/labels/"
undetected_dir = "/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output_test/undetected/"

# Define class names and corresponding prompts
#class_names = ["class1", "class2", "class3", "class4", "class5", "class6", "class7", "class8", "class9", "class10", "class11"]
#prompts = ["prompt1", "prompt2", "prompt3", "prompt4", "prompt5", "prompt6", "prompt7", "prompt8", "prompt9", "prompt10", "prompt11"]

class_names = ["cardboard", "paper", "plastic", "metal", "medical", "clothes", "furniture", "shoes", "biowaste", "e-waste", "glass"]

prompts = ["cardboard or cardboard box or brown cardboard",
          "paper or stacked paper cups or newspaper",
          "plastic or stacked plastic cups or plastic containers",
          "shiny object",
          "medicine or syringe or mask or gloves or capsule or tablet",
          "clothes or shoes or hair accessory or shirt or trouser or skirt or tie or belt or cap or hat",
          "furniture",
          "shoes or footwear or sandals or boots or flipflops",
          "food or rotten fruit or fruit peels or rotten vegetables or dairy or meat or poultry or seeds",
          "electronic or mobile or laptop or wires or motherboard or electronic chip or battery or semiconductor or cable or switch or charger or appliance",
          "glass or colorful glass or bottles"]

# Load class IDs
class_ids = {class_name: idx for idx, class_name in enumerate(class_names)}

# Initialize counters
undetected_count = 0

# Iterate through each class
for class_name, prompt in zip(class_names, prompts):
    class_dir = os.path.join(base_dir, class_name)

    # Get the initial number of images
    initial_image_count = len([filename for filename in os.listdir(class_dir) if filename.endswith(".jpg")])

    print(f"Processing images in {class_name} folder")

    # Create output folders if they don't exist
    os.makedirs(output_images_dir, exist_ok=True)
    os.makedirs(output_labels_dir, exist_ok=True)

    # Initialize lists to store undetected images
    undetected_images = []

    # Iterate through each image in the class folder
    for filename in os.listdir(class_dir):
        if filename.endswith(".jpg"):
            image_path = os.path.join(class_dir, filename)

            # Check if the corresponding text file already exists
            label_filename = os.path.splitext(filename)[0] + ".txt"
            label_filepath = os.path.join(output_labels_dir, label_filename)

            try:
                # Process the image and get bounding boxes
                image_source, image = load_image(image_path)
                boxes, _, _ = predict(model=model, image=image, caption=prompt, box_threshold=0.5, text_threshold=0.25)

                # Get class ID
                class_id = class_ids[class_name]

                # Check if the bounding boxes are detected
                if boxes.numel() > 0:
                    # Copy the image to the output folder
                    output_image_path = os.path.join(output_images_dir, filename)
                    shutil.copy(image_path, output_image_path)

                    # Write bounding box information to the text file
                    with open(label_filepath, "w") as label_file:
                        for box in boxes:
                            x_center, y_center, width, height = box.tolist()
                            entry = f"{class_id} {x_center} {y_center} {width} {height}\n"
                            label_file.write(entry)
                else:
                    # If no boxes are detected, move the image to the undetected folder
                    undetected_images.append(image_path)

            except UnidentifiedImageError as e:
                print(f"Error processing image: {image_path}")
                print(f"Error details: {e}")
                continue

    # Move undetected images to the undetected folder
    undetected_class_dir = os.path.join(undetected_dir, f"undetected_{class_name}")
    os.makedirs(undetected_class_dir, exist_ok=True)
    for undetected_image in undetected_images:
        shutil.copy(undetected_image, undetected_class_dir)

    # Print statistics
    print(f"Initial number of images in {class_name} folder: {initial_image_count}")
    print(f"Images with bounding boxes detected: {initial_image_count - len(undetected_images)}")
    print(f"Undetected images: {len(undetected_images)}")

#Copy the above file to the train_val_test to data/test/images and data/test/labels

import os
import shutil

# Define source and destination directories
source_images_dir = '/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output_test/images/' #should be output_test now
source_labels_dir = '/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/output_test/labels/'
destination_images_dir = '/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/data/test/images/'
destination_labels_dir = '/content/drive/MyDrive/Data298AandB/Grounding_DINO/train_val_test/data/test/labels/'

# Create destination directories if they don't exist
os.makedirs(destination_images_dir, exist_ok=True)
os.makedirs(destination_labels_dir, exist_ok=True)

# Get list of image files
image_files = os.listdir(source_images_dir)

# Copy image files
for image_file in image_files:
    source_image_path = os.path.join(source_images_dir, image_file)
    destination_image_path = os.path.join(destination_images_dir, image_file)
    if not os.path.exists(destination_image_path):
        shutil.copyfile(source_image_path, destination_image_path)
        print(f"Copied {source_image_path} to {destination_image_path}")

# Get list of label files
label_files = os.listdir(source_labels_dir)

# Copy label files
for label_file in label_files:
    source_label_path = os.path.join(source_labels_dir, label_file)
    destination_label_path = os.path.join(destination_labels_dir, label_file)
    if not os.path.exists(destination_label_path):
        shutil.copyfile(source_label_path, destination_label_path)
        print(f"Copied {source_label_path} to {destination_label_path}")







